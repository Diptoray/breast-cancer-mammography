{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"DeepLearningProject.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BrkLnRgBXrBA"},"source":["# Final Project\n","\n","## Predict whether a mammogram mass is benign or malignant\n","\n","We'll be using the \"mammographic masses\" public dataset from the UCI repository (source: https://archive.ics.uci.edu/ml/datasets/Mammographic+Mass)\n","\n","This data contains 961 instances of masses detected in mammograms, and contains the following attributes:\n","\n","\n","   1. BI-RADS assessment: 1 to 5 (ordinal)  \n","   2. Age: patient's age in years (integer)\n","   3. Shape: mass shape: round=1 oval=2 lobular=3 irregular=4 (nominal)\n","   4. Margin: mass margin: circumscribed=1 microlobulated=2 obscured=3 ill-defined=4 spiculated=5 (nominal)\n","   5. Density: mass density high=1 iso=2 low=3 fat-containing=4 (ordinal)\n","   6. Severity: benign=0 or malignant=1 (binominal)\n","   \n","BI-RADS is an assesment of how confident the severity classification is; it is not a \"predictive\" attribute and so we will discard it. The age, shape, margin, and density attributes are the features that we will build our model with, and \"severity\" is the classification we will attempt to predict based on those attributes.\n","\n","Although \"shape\" and \"margin\" are nominal data types, which sklearn typically doesn't deal with well, they are close enough to ordinal that we shouldn't just discard them. The \"shape\" for example is ordered increasingly from round to irregular.\n","\n","A lot of unnecessary anguish and surgery arises from false positives arising from mammogram results. If we can build a better way to interpret them through supervised machine learning, it could improve a lot of lives.\n","\n","## Your assignment\n","\n","Build a Multi-Layer Perceptron and train it to classify masses as benign or malignant based on its features.\n","\n","The data needs to be cleaned; many rows contain missing data, and there may be erroneous data identifiable as outliers as well.\n","\n","Remember to normalize your data first! And experiment with different topologies, optimizers, and hyperparameters.\n","\n","I was able to achieve over 80% accuracy - can you beat that?\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"myIPk3vKXrBD"},"source":["## Let's begin: prepare your data\n","\n","Start by importing the mammographic_masses.data.txt file into a Pandas dataframe (hint: use read_csv) and take a look at it."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"X9fXKUJ5XrBE","colab":{}},"source":["import pandas as pd\n","from sklearn import preprocessing\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HEKWdkVeXrBK"},"source":["Make sure you use the optional parmaters in read_csv to convert missing data (indicated by a ?) into NaN, and to add the appropriate column names (BI_RADS, age, shape, margin, density, and severity):"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xW849r5cXrBL","colab":{}},"source":["data = pd.read_csv('mammographic_masses.data.txt', header = None, names = ['BI-RADS assessment','Age','Shape','Margin','Density','Severity'], na_values='?', keep_default_na = True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QB75JsrkXrBP"},"source":["Evaluate whether the data needs cleaning; your model is only as good as the data it's given. Hint: use describe() on the dataframe."]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1564191219080,"user_tz":-330,"elapsed":811,"user":{"displayName":"Soumyadipto Ray","photoUrl":"https://lh6.googleusercontent.com/-Zs0ki6xOKj8/AAAAAAAAAAI/AAAAAAAAAC4/mg4ufir6y2o/s64/photo.jpg","userId":"17520023616941727964"}},"id":"bMcHBtppXrBQ","outputId":"ba444c94-df56-4489-b81a-6535158b2080","colab":{"base_uri":"https://localhost:8080/","height":297}},"source":["data.describe()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>BI-RADS assessment</th>\n","      <th>Age</th>\n","      <th>Shape</th>\n","      <th>Margin</th>\n","      <th>Density</th>\n","      <th>Severity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>959.000000</td>\n","      <td>956.000000</td>\n","      <td>930.000000</td>\n","      <td>913.000000</td>\n","      <td>885.000000</td>\n","      <td>961.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>4.348279</td>\n","      <td>55.487448</td>\n","      <td>2.721505</td>\n","      <td>2.796276</td>\n","      <td>2.910734</td>\n","      <td>0.463059</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>1.783031</td>\n","      <td>14.480131</td>\n","      <td>1.242792</td>\n","      <td>1.566546</td>\n","      <td>0.380444</td>\n","      <td>0.498893</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","      <td>18.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>4.000000</td>\n","      <td>45.000000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>4.000000</td>\n","      <td>57.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>5.000000</td>\n","      <td>66.000000</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>55.000000</td>\n","      <td>96.000000</td>\n","      <td>4.000000</td>\n","      <td>5.000000</td>\n","      <td>4.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       BI-RADS assessment         Age  ...     Density    Severity\n","count          959.000000  956.000000  ...  885.000000  961.000000\n","mean             4.348279   55.487448  ...    2.910734    0.463059\n","std              1.783031   14.480131  ...    0.380444    0.498893\n","min              0.000000   18.000000  ...    1.000000    0.000000\n","25%              4.000000   45.000000  ...    3.000000    0.000000\n","50%              4.000000   57.000000  ...    3.000000    0.000000\n","75%              5.000000   66.000000  ...    3.000000    1.000000\n","max             55.000000   96.000000  ...    4.000000    1.000000\n","\n","[8 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"v10nP4_LXrBU"},"source":["There are quite a few missing values in the data set. Before we just drop every row that's missing data, let's make sure we don't bias our data in doing so. Does there appear to be any sort of correlation to what sort of data has missing fields? If there were, we'd have to try and go back and fill that data in."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DQgZn76yXrBV","colab":{}},"source":["data = data.drop(labels = 'BI-RADS assessment', axis = 1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mguRT3K6XrBZ"},"source":["If the missing data seems randomly distributed, go ahead and drop rows with missing data. Hint: use dropna()."]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1564191330921,"user_tz":-330,"elapsed":816,"user":{"displayName":"Soumyadipto Ray","photoUrl":"https://lh6.googleusercontent.com/-Zs0ki6xOKj8/AAAAAAAAAAI/AAAAAAAAAC4/mg4ufir6y2o/s64/photo.jpg","userId":"17520023616941727964"}},"id":"J7xJFKAss1ht","outputId":"8b20f8f5-617b-498b-d6b5-64527972f2a6","colab":{"base_uri":"https://localhost:8080/","height":297}},"source":["data.describe()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>Shape</th>\n","      <th>Margin</th>\n","      <th>Density</th>\n","      <th>Severity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>956.000000</td>\n","      <td>930.000000</td>\n","      <td>913.000000</td>\n","      <td>885.000000</td>\n","      <td>961.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>55.487448</td>\n","      <td>2.721505</td>\n","      <td>2.796276</td>\n","      <td>2.910734</td>\n","      <td>0.463059</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>14.480131</td>\n","      <td>1.242792</td>\n","      <td>1.566546</td>\n","      <td>0.380444</td>\n","      <td>0.498893</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>18.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>45.000000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>57.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>3.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>66.000000</td>\n","      <td>4.000000</td>\n","      <td>4.000000</td>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>96.000000</td>\n","      <td>4.000000</td>\n","      <td>5.000000</td>\n","      <td>4.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              Age       Shape      Margin     Density    Severity\n","count  956.000000  930.000000  913.000000  885.000000  961.000000\n","mean    55.487448    2.721505    2.796276    2.910734    0.463059\n","std     14.480131    1.242792    1.566546    0.380444    0.498893\n","min     18.000000    1.000000    1.000000    1.000000    0.000000\n","25%     45.000000    2.000000    1.000000    3.000000    0.000000\n","50%     57.000000    3.000000    3.000000    3.000000    0.000000\n","75%     66.000000    4.000000    4.000000    3.000000    1.000000\n","max     96.000000    4.000000    5.000000    4.000000    1.000000"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rr2RIcnJXrBb","colab":{}},"source":["data.dropna(inplace = True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","collapsed":true,"id":"u848UvtOXrBf"},"source":["Next you'll need to convert the Pandas dataframes into numpy arrays that can be used by scikit_learn. Create an array that extracts only the feature data we want to work with (age, shape, margin, and density) and another array that contains the classes (severity). You'll also need an array of the feature name labels."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YjwmpskAXrBg","colab":{}},"source":["feature_names = ['Age','Shape','Margin','Density','Severity']\n","all_features = data[feature_names].drop('Severity', axis=1).values\n","all_classes = data['Severity'].values"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"KEaLxCQQXrBm"},"source":["Some of our models require the input data to be normalized, so go ahead and normalize the attribute data. Hint: use preprocessing.StandardScaler()."]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1564191349994,"user_tz":-330,"elapsed":807,"user":{"displayName":"Soumyadipto Ray","photoUrl":"https://lh6.googleusercontent.com/-Zs0ki6xOKj8/AAAAAAAAAAI/AAAAAAAAAC4/mg4ufir6y2o/s64/photo.jpg","userId":"17520023616941727964"}},"id":"aXuBHAcpXrBo","outputId":"9dbcaa2f-7730-4246-c525-56115971e880","colab":{"base_uri":"https://localhost:8080/","height":136}},"source":[" preprocessing.StandardScaler().fit_transform(all_features)"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0.76580356,  0.17445989,  1.39563127,  0.24031298],\n","       [ 0.15166622,  0.97988304,  1.39563127,  0.24031298],\n","       [-1.89545824, -1.43638642, -1.15892729,  0.24031298],\n","       ...,\n","       [ 0.56109111,  0.97988304,  1.39563127,  0.24031298],\n","       [ 0.69756608,  0.97988304,  1.39563127,  0.24031298],\n","       [ 0.42461615,  0.17445989,  0.11835199,  0.24031298]])"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kW40RTogXrBv"},"source":["## Now build your neural network.\n","\n","Now set up an actual MLP model using Keras:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MiZS1-kAXrBy","colab":{}},"source":["import tensorflow as tf\n","from tensorflow.keras.backend import set_session\n","config = tf.ConfigProto()\n","config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n","sess = tf.Session(config=config)\n","set_session(sess)  # set this TensorFlow session as the default session for Keras"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1564191447605,"user_tz":-330,"elapsed":74400,"user":{"displayName":"Soumyadipto Ray","photoUrl":"https://lh6.googleusercontent.com/-Zs0ki6xOKj8/AAAAAAAAAAI/AAAAAAAAAC4/mg4ufir6y2o/s64/photo.jpg","userId":"17520023616941727964"}},"id":"n71Oaw1PXrB6","outputId":"9da16a42-cecb-4ba8-f410-6f308a62174a","colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.models import Sequential\n","from sklearn.model_selection import cross_val_score\n","\n","def create_model():\n","    model = Sequential()\n","    #4 feature inputs going into an 64-unit layer \n","    model.add(Dense(64, input_dim=4, kernel_initializer='normal', activation='relu'))\n","    \n","    # Another hidden layer of 16 units\n","    model.add(Dense(16, kernel_initializer='normal', activation='relu'))\n","    \n","   \n","    \n","    # Another hidden layer of 16 units\n","    model.add(Dense(16, kernel_initializer='normal', activation='relu'))\n","    \n","    # Another hidden layer of 16 or 8 units\n","    model.add(Dense(16, kernel_initializer='normal', activation='relu'))\n","    \n","      \n","    # Output layer with a binary classification (Benign or Malignant diagnosis)\n","    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n","    # Compile model\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    return model\n","\n","from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n","\n","# Wrap our Keras model in an estimator compatible with scikit_learn\n","estimator = KerasClassifier(build_fn=create_model, epochs=100, verbose=0)\n","# Now we can use scikit_learn's cross_val_score to evaluate this model identically to the others\n","cv_scores = cross_val_score(estimator, all_features, all_classes, cv=10)\n","cv_scores.mean()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0727 01:36:08.277575 139955810207616 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0727 01:36:08.392845 139955810207616 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["0.795496267080307"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"colab_type":"text","collapsed":true,"id":"UjmoACi9XrCA"},"source":["## How did you do?\n","\n","Which topology, and which choice of hyperparameters, performed the best? Feel free to share your results!"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"64qT8yJFXrCC","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}